{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R_gmxdG_Wvo",
        "outputId": "b7a034a9-3e75-4846-d640-153137369e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/13.6 MB\u001b[0m \u001b[31m236.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m230.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m130.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!pip -q install decord==0.6.0\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y unrar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkmn_FkWuAG1",
        "outputId": "071ace07-afd3-4731-c8be-1acd146c9966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing tools...\n",
            "=== Attempt 1: HuggingFace ===\n",
            "Downloading: UCF-101.zip\n",
            "Downloaded 6.5G -> UCF-101.zip\n",
            "Downloading: splits.zip\n",
            "Downloaded 112K -> splits.zip\n",
            "Extracting HF zip...\n",
            "Extracting splits...\n",
            "\n",
            "=== DONE extracting ===\n",
            "Root: /content/ucf101\n",
            "Listing key folders:\n",
            "total 6.5G\n",
            "drwxr-xr-x 4 root root 4.0K Jan 12 20:04 .\n",
            "drwxr-xr-x 1 root root 4.0K Jan 12 20:01 ..\n",
            "drwxr-xr-x 3 root root 4.0K Jan 12 20:05 splits\n",
            "-rw-r--r-- 1 root root 112K Jan 12 20:04 splits.zip\n",
            "-rw-r--r-- 1 root root 6.5G Jan 12 20:03 UCF-101.zip\n",
            "drwxr-xr-x 3 root root 4.0K Jan 12 20:04 videos\n",
            "\n",
            "Counting videos (.avi):\n",
            "13320\n",
            "\n",
            "Split files:\n",
            "total 1.6M\n",
            "drwxr-xr-x 2 root root 4.0K Jul 21  2013 .\n",
            "drwxr-xr-x 3 root root 4.0K Jan 12 20:05 ..\n",
            "-rw-r--r-- 1 root root 1.6K Jul  4  2013 classInd.txt\n",
            "-rw-r--r-- 1 root root 143K Jul 21  2013 testlist01.txt\n",
            "-rw-r--r-- 1 root root 141K Jul 21  2013 testlist02.txt\n",
            "-rw-r--r-- 1 root root 140K Jul 21  2013 testlist03.txt\n",
            "-rw-r--r-- 1 root root 386K Jul 21  2013 trainlist01.txt\n",
            "-rw-r--r-- 1 root root 389K Jul 21  2013 trainlist02.txt\n",
            "-rw-r--r-- 1 root root 390K Jul 21  2013 trainlist03.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1082  100  1082    0     0   3013      0 --:--:-- --:--:-- --:--:--  3022\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 6635M    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r  0 6635M    0 22.4M    0     0  9283k      0  0:12:11  0:00:02  0:12:09 11.7M\r  1 6635M    1  116M    0     0  33.2M      0  0:03:19  0:00:03  0:03:16 39.6M\r  2 6635M    2  192M    0     0  42.9M      0  0:02:34  0:00:04  0:02:30 49.1M\r  4 6635M    4  307M    0     0  56.1M      0  0:01:58  0:00:05  0:01:53 62.5M\r  6 6635M    6  400M    0     0  61.1M      0  0:01:48  0:00:06  0:01:42 82.0M\r  7 6635M    7  510M    0     0  68.3M      0  0:01:37  0:00:07  0:01:30 97.6M\r  8 6635M    8  584M    0     0  68.7M      0  0:01:36  0:00:08  0:01:28 93.6M\r  9 6635M    9  640M    0     0  65.7M      0  0:01:40  0:00:09  0:01:31 85.0M\r 10 6635M   10  704M    0     0  63.0M      0  0:01:45  0:00:11  0:01:34 69.6M\r 11 6635M   11  740M    0     0  64.5M      0  0:01:42  0:00:11  0:01:31 69.0M\r 11 6635M   11  788M    0     0  63.2M      0  0:01:44  0:00:12  0:01:32 55.5M\r 12 6635M   12  837M    0     0  62.1M      0  0:01:46  0:00:13  0:01:33 50.8M\r 13 6635M   13  896M    0     0  60.5M      0  0:01:49  0:00:14  0:01:35 50.6M\r 14 6635M   14  960M    0     0  61.7M      0  0:01:47  0:00:15  0:01:32 58.2M\r 15 6635M   15 1024M    0     0  62.0M      0  0:01:46  0:00:16  0:01:30 56.4M\r 16 6635M   16 1090M    0     0  62.3M      0  0:01:46  0:00:17  0:01:29 60.2M\r 17 6635M   17 1152M    0     0  61.5M      0  0:01:47  0:00:18  0:01:29 60.1M\r 18 6635M   18 1216M    0     0  60.3M      0  0:01:49  0:00:20  0:01:29 59.8M\r 18 6635M   18 1252M    0     0  61.1M      0  0:01:48  0:00:20  0:01:28 59.3M\r 19 6635M   19 1297M    0     0  60.4M      0  0:01:49  0:00:21  0:01:28 54.8M\r 20 6635M   20 1344M    0     0  59.5M      0  0:01:51  0:00:22  0:01:29 49.7M\r 21 6635M   21 1408M    0     0  58.5M      0  0:01:53  0:00:24  0:01:29 47.7M\r 21 6635M   21 1455M    0     0  59.4M      0  0:01:51  0:00:24  0:01:27 55.2M\r 22 6635M   22 1480M    0     0  58.0M      0  0:01:54  0:00:25  0:01:29 45.6M\r 23 6635M   23 1562M    0     0  58.9M      0  0:01:52  0:00:26  0:01:26 52.9M\r 24 6635M   24 1600M    0     0  57.8M      0  0:01:54  0:00:27  0:01:27 50.5M\r 25 6635M   25 1664M    0     0  58.3M      0  0:01:53  0:00:28  0:01:25 57.5M\r 26 6635M   26 1729M    0     0  58.6M      0  0:01:53  0:00:29  0:01:24 54.7M\r 27 6635M   27 1831M    0     0  60.1M      0  0:01:50  0:00:30  0:01:20 70.3M\r 28 6635M   28 1895M    0     0  60.2M      0  0:01:50  0:00:31  0:01:19 66.6M\r 29 6635M   29 1981M    0     0  61.0M      0  0:01:48  0:00:32  0:01:16 79.2M\r 31 6635M   31 2102M    0     0  62.8M      0  0:01:45  0:00:33  0:01:12 88.4M\r 33 6635M   33 2217M    0     0  64.3M      0  0:01:43  0:00:34  0:01:09 97.5M\r 34 6635M   34 2300M    0     0  64.8M      0  0:01:42  0:00:35  0:01:07 93.7M\r 36 6635M   36 2415M    0     0  66.2M      0  0:01:40  0:00:36  0:01:04  104M\r 38 6635M   38 2536M    0     0  67.6M      0  0:01:38  0:00:37  0:01:01  110M\r 40 6635M   40 2658M    0     0  69.1M      0  0:01:36  0:00:38  0:00:58  111M\r 41 6635M   41 2751M    0     0  69.6M      0  0:01:35  0:00:39  0:00:56  106M\r 43 6635M   43 2874M    0     0  71.0M      0  0:01:33  0:00:40  0:00:53  114M\r 45 6635M   45 2988M    0     0  72.0M      0  0:01:32  0:00:41  0:00:51  114M\r 46 6635M   46 3086M    0     0  72.6M      0  0:01:31  0:00:42  0:00:49  110M\r 48 6635M   48 3207M    0     0  73.7M      0  0:01:29  0:00:43  0:00:46  109M\r 50 6635M   50 3325M    0     0  74.7M      0  0:01:28  0:00:44  0:00:44  114M\r 51 6635M   51 3441M    0     0  75.6M      0  0:01:27  0:00:45  0:00:42  113M\r 53 6635M   53 3565M    0     0  76.7M      0  0:01:26  0:00:46  0:00:40  115M\r 55 6635M   55 3655M    0     0  77.0M      0  0:01:26  0:00:47  0:00:39  113M\r 56 6635M   56 3780M    0     0  77.9M      0  0:01:25  0:00:48  0:00:37  114M\r 59 6635M   59 3915M    0     0  79.1M      0  0:01:23  0:00:49  0:00:34  117M\r 60 6635M   60 4045M    0     0  80.1M      0  0:01:22  0:00:50  0:00:32  120M\r 62 6635M   62 4121M    0     0  80.0M      0  0:01:22  0:00:51  0:00:31  111M\r 63 6635M   63 4188M    0     0  79.8M      0  0:01:23  0:00:52  0:00:31  106M\r 64 6635M   64 4288M    0     0  79.6M      0  0:01:23  0:00:53  0:00:30 94.9M\r 65 6635M   65 4352M    0     0  79.7M      0  0:01:23  0:00:54  0:00:29 85.2M\r 65 6635M   65 4353M    0     0  75.4M      0  0:01:27  0:00:57  0:00:30 42.4M\r 67 6635M   67 4453M    0     0  76.1M      0  0:01:27  0:00:58  0:00:29 47.4M\r 68 6635M   68 4525M    0     0  76.0M      0  0:01:27  0:00:59  0:00:28 48.0M\r 70 6635M   70 4656M    0     0  76.9M      0  0:01:26  0:01:00  0:00:26 55.3M\r 71 6635M   71 4736M    0     0  77.0M      0  0:01:26  0:01:01  0:00:25 55.9M\r 73 6635M   73 4863M    0     0  77.8M      0  0:01:25  0:01:02  0:00:23  107M\r 75 6635M   75 5009M    0     0  78.9M      0  0:01:24  0:01:03  0:00:21  111M\r 77 6635M   77 5132M    0     0  79.5M      0  0:01:23  0:01:04  0:00:19  120M\r 78 6635M   78 5218M    0     0  79.6M      0  0:01:23  0:01:05  0:00:18  111M\r 80 6635M   80 5313M    0     0  79.9M      0  0:01:23  0:01:06  0:00:17  115M\r 82 6635M   82 5449M    0     0  80.7M      0  0:01:22  0:01:07  0:00:15  116M\r 83 6635M   83 5553M    0     0  81.1M      0  0:01:21  0:01:08  0:00:13  108M\r 85 6635M   85 5687M    0     0  81.8M      0  0:01:21  0:01:09  0:00:12  111M\r 87 6635M   87 5773M    0     0  81.9M      0  0:01:20  0:01:10  0:00:10  111M\r 88 6635M   88 5895M    0     0  82.4M      0  0:01:20  0:01:11  0:00:09  116M\r 90 6635M   90 6034M    0     0  83.2M      0  0:01:19  0:01:12  0:00:07  117M\r 92 6635M   92 6151M    0     0  83.7M      0  0:01:19  0:01:13  0:00:06  119M\r 94 6635M   94 6252M    0     0  83.3M      0  0:01:19  0:01:15  0:00:04  102M\r 94 6635M   94 6291M    0     0  83.3M      0  0:01:19  0:01:15  0:00:04  103M\r 96 6635M   96 6411M    0     0  83.8M      0  0:01:19  0:01:16  0:00:03  103M\r 97 6635M   97 6499M    0     0  83.8M      0  0:01:19  0:01:17  0:00:02 93.0M\r 99 6635M   99 6572M    0     0  83.7M      0  0:01:19  0:01:18  0:00:01 84.2M\r100 6635M  100 6635M    0     0  84.0M      0  0:01:18  0:01:18 --:--:-- 96.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1134  100  1134    0     0   3730      0 --:--:-- --:--:-- --:--:--  3742\n",
            "\r 26  111k   26 30264    0     0  30268      0  0:00:03 --:--:--  0:00:03 30268\r100  111k  100  111k    0     0   111k      0  0:00:01  0:00:01 --:--:-- 79.8M\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -u  # don't exit on error; we handle errors ourselves\n",
        "\n",
        "ROOT=\"/content/ucf101\"\n",
        "mkdir -p \"$ROOT\"\n",
        "cd \"$ROOT\"\n",
        "\n",
        "echo \"Installing tools...\"\n",
        "apt-get -qq update\n",
        "apt-get -qq install -y curl unzip wget unrar > /dev/null\n",
        "\n",
        "download_with_curl () {\n",
        "  URL=\"$1\"\n",
        "  OUT=\"$2\"\n",
        "  echo \"Downloading: $OUT\"\n",
        "  rm -f \"$OUT.part\" \"$OUT\"\n",
        "  # -L follow redirects, --fail fail on HTTP errors, retry on transient issues\n",
        "  curl -L --fail --retry 8 --retry-delay 2 --connect-timeout 20 --max-time 0 \\\n",
        "    -o \"$OUT.part\" \"$URL\"\n",
        "  mv \"$OUT.part\" \"$OUT\"\n",
        "  echo \"Downloaded $(ls -lh \"$OUT\" | awk '{print $5}') -> $OUT\"\n",
        "  return 0\n",
        "}\n",
        "\n",
        "is_valid_zip () {\n",
        "  FILE=\"$1\"\n",
        "  unzip -tq \"$FILE\" >/dev/null 2>&1\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Try Hugging Face mirror\n",
        "# ---------------------------\n",
        "HF_VID=\"https://huggingface.co/datasets/quchenyuan/UCF101-ZIP/resolve/main/UCF-101.zip?download=true\"\n",
        "HF_SPL=\"https://huggingface.co/datasets/quchenyuan/UCF101-ZIP/resolve/main/UCF101TrainTestSplits-RecognitionTask.zip?download=true\"\n",
        "\n",
        "OK_VID=0\n",
        "OK_SPL=0\n",
        "\n",
        "echo \"=== Attempt 1: HuggingFace ===\"\n",
        "download_with_curl \"$HF_VID\" \"UCF-101.zip\" && is_valid_zip \"UCF-101.zip\" && OK_VID=1 || OK_VID=0\n",
        "download_with_curl \"$HF_SPL\" \"splits.zip\"  && is_valid_zip \"splits.zip\"  && OK_SPL=1 || OK_SPL=0\n",
        "\n",
        "# If HF video zip is invalid, show what it actually is (often HTML)\n",
        "if [ \"$OK_VID\" -ne 1 ] && [ -f \"UCF-101.zip\" ]; then\n",
        "  echo \"HF video file not a valid zip. 'file' says:\"\n",
        "  file \"UCF-101.zip\" || true\n",
        "fi\n",
        "if [ \"$OK_SPL\" -ne 1 ] && [ -f \"splits.zip\" ]; then\n",
        "  echo \"HF splits file not a valid zip. 'file' says:\"\n",
        "  file \"splits.zip\" || true\n",
        "fi\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Fallback to official CRCV\n",
        "# ---------------------------\n",
        "CRCV_VID=\"http://www.crcv.ucf.edu/data/UCF101/UCF101.rar\"\n",
        "CRCV_SPL=\"http://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip\"\n",
        "\n",
        "if [ \"$OK_VID\" -ne 1 ]; then\n",
        "  echo \"=== Attempt 2: CRCV (official) video rar ===\"\n",
        "  rm -f UCF101.rar\n",
        "  # wget tends to work on http CRCV\n",
        "  wget -O UCF101.rar \"$CRCV_VID\"\n",
        "  # quick sanity: list archive\n",
        "  unrar t UCF101.rar >/dev/null 2>&1 && OK_VID=2 || OK_VID=0\n",
        "fi\n",
        "\n",
        "if [ \"$OK_SPL\" -ne 1 ]; then\n",
        "  echo \"=== Attempt 2: CRCV (official) splits zip ===\"\n",
        "  wget -O splits.zip \"$CRCV_SPL\"\n",
        "  is_valid_zip \"splits.zip\" && OK_SPL=2 || OK_SPL=0\n",
        "fi\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Extract\n",
        "# ---------------------------\n",
        "mkdir -p videos\n",
        "mkdir -p splits\n",
        "\n",
        "if [ \"$OK_VID\" -eq 1 ]; then\n",
        "  echo \"Extracting HF zip...\"\n",
        "  unzip -q -o \"UCF-101.zip\" -d \"videos\"\n",
        "elif [ \"$OK_VID\" -eq 2 ]; then\n",
        "  echo \"Extracting CRCV rar...\"\n",
        "  unrar x -idq -o+ \"UCF101.rar\" \"videos/\"\n",
        "else\n",
        "  echo \"ERROR: Could not download a valid UCF101 video archive from HF or CRCV.\"\n",
        "  echo \"Try: Runtime -> Disconnect and delete runtime, then run again.\"\n",
        "  exit 1\n",
        "fi\n",
        "\n",
        "if [ \"$OK_SPL\" -ge 1 ]; then\n",
        "  echo \"Extracting splits...\"\n",
        "  unzip -q -o \"splits.zip\" -d \"splits\"\n",
        "else\n",
        "  echo \"ERROR: Could not download valid splits.zip.\"\n",
        "  exit 1\n",
        "fi\n",
        "\n",
        "echo \"\"\n",
        "echo \"=== DONE extracting ===\"\n",
        "echo \"Root: $ROOT\"\n",
        "echo \"Listing key folders:\"\n",
        "ls -lah \"$ROOT\" | head -n 30\n",
        "\n",
        "echo \"\"\n",
        "echo \"Counting videos (.avi):\"\n",
        "find \"$ROOT/videos\" -type f -name \"*.avi\" | wc -l\n",
        "\n",
        "echo \"\"\n",
        "echo \"Split files:\"\n",
        "ls -lah \"$ROOT/splits/ucfTrainTestlist\" | head -n 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MbZn0_upKgy",
        "outputId": "5174792d-74e7-4bc1-b4d2-f4ecb162783d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPLITS_DIR exists: True /content/ucf101/splits/ucfTrainTestlist\n",
            "VIDEOS_ROOT: /content/ucf101/videos/UCF-101\n",
            "Example videos: ['/content/ucf101/videos/UCF-101/JugglingBalls/v_JugglingBalls_g20_c03.avi', '/content/ucf101/videos/UCF-101/JugglingBalls/v_JugglingBalls_g14_c05.avi', '/content/ucf101/videos/UCF-101/JugglingBalls/v_JugglingBalls_g25_c02.avi']\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "\n",
        "ROOT = \"/content/ucf101\"\n",
        "\n",
        "# Splits dir (this should exist if extraction worked)\n",
        "SPLITS_DIR = os.path.join(ROOT, \"splits\", \"ucfTrainTestlist\")\n",
        "print(\"SPLITS_DIR exists:\", os.path.isdir(SPLITS_DIR), SPLITS_DIR)\n",
        "\n",
        "# Try common video roots\n",
        "candidates = [\n",
        "    os.path.join(ROOT, \"videos\", \"UCF101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"UCF-101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"UCF101\", \"UCF101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"UCF-101\", \"UCF-101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"videos\", \"UCF101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"videos\", \"UCF-101\"),\n",
        "]\n",
        "\n",
        "VIDEOS_ROOT = None\n",
        "for p in candidates:\n",
        "    if os.path.isdir(p) and len(glob.glob(os.path.join(p, \"*\", \"*.avi\"))) > 0:\n",
        "        VIDEOS_ROOT = p\n",
        "        break\n",
        "\n",
        "print(\"VIDEOS_ROOT:\", VIDEOS_ROOT)\n",
        "print(\"Example videos:\", glob.glob(os.path.join(VIDEOS_ROOT, \"*\", \"*.avi\"))[:3] if VIDEOS_ROOT else None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIfq_Ns6t__R",
        "outputId": "92dbe3dc-a64c-46d8-b442-bb73980ad97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda NVIDIA A100-SXM4-80GB\n",
            "VIDEOS_ROOT: /content/ucf101/videos/UCF-101\n",
            "SPLITS_DIR: /content/ucf101/splits/ucfTrainTestlist\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'frames': 32,\n",
              " 'stride': 2,\n",
              " 'size': 160,\n",
              " 'batch': 24,\n",
              " 'workers': 4,\n",
              " 'epochs': 100,\n",
              " 'lr': 0.12,\n",
              " 'warmup_epochs': 5,\n",
              " 'weight_decay': 0.0001,\n",
              " 'label_smoothing': 0.1,\n",
              " 'grad_accum': 1,\n",
              " 'nclips_eval': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os, random, math, glob\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "ROOT = \"/content/ucf101\"\n",
        "SPLITS_DIR  = os.path.join(ROOT, \"splits\", \"ucfTrainTestlist\")\n",
        "\n",
        "# Auto-detect VIDEOS_ROOT (works for different unzip/extract layouts)\n",
        "candidates = [\n",
        "    os.path.join(ROOT, \"videos\", \"UCF101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"UCF-101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"UCF101\", \"UCF101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"UCF-101\", \"UCF-101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"videos\", \"UCF101\"),\n",
        "    os.path.join(ROOT, \"videos\", \"videos\", \"UCF-101\"),\n",
        "]\n",
        "\n",
        "VIDEOS_ROOT = None\n",
        "for p in candidates:\n",
        "    if os.path.isdir(p) and len(glob.glob(os.path.join(p, \"*\", \"*.avi\"))) > 0:\n",
        "        VIDEOS_ROOT = p\n",
        "        break\n",
        "\n",
        "if VIDEOS_ROOT is None:\n",
        "    raise FileNotFoundError(\"Could not find UCF101 videos folder. Check /content/ucf101/videos/\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device, torch.cuda.get_device_name(0) if device == \"cuda\" else \"\")\n",
        "print(\"VIDEOS_ROOT:\", VIDEOS_ROOT)\n",
        "print(\"SPLITS_DIR:\", SPLITS_DIR)\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "# --- Choose ONE preset ---\n",
        "PRESET = \"STRONG\"   # \"FAST\" or \"STRONG\"\n",
        "\n",
        "if PRESET == \"FAST\":\n",
        "    CFG = dict(\n",
        "        frames=16, stride=2, size=112,\n",
        "        batch=64, workers=4,\n",
        "        epochs=60, lr=0.2, warmup_epochs=5,\n",
        "        weight_decay=1e-4, label_smoothing=0.1,\n",
        "        grad_accum=1,\n",
        "        nclips_eval=10\n",
        "    )\n",
        "else:  # STRONG\n",
        "    CFG = dict(\n",
        "        frames=32, stride=2, size=160,\n",
        "        batch=24, workers=4,\n",
        "        epochs=100, lr=0.12, warmup_epochs=5,\n",
        "        weight_decay=1e-4, label_smoothing=0.1,\n",
        "        grad_accum=1,   # set to 2 if you hit OOM\n",
        "        nclips_eval=10\n",
        "    )\n",
        "\n",
        "CFG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJz4Muf1t_4P",
        "outputId": "b2612cd8-ef85-4133-8bd0-5f5bfb6ccec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 9537 Test videos: 3783\n",
            "Example: ('ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi', 0)\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def read_class_index(path: str) -> Dict[str, int]:\n",
        "    # classInd.txt: \"1 ApplyEyeMakeup\"\n",
        "    mapping = {}\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            idx, name = line.strip().split()\n",
        "            mapping[name] = int(idx) - 1\n",
        "    return mapping\n",
        "\n",
        "CLASS_TO_IDX = read_class_index(os.path.join(SPLITS_DIR, \"classInd.txt\"))\n",
        "IDX_TO_CLASS = {v:k for k,v in CLASS_TO_IDX.items()}\n",
        "\n",
        "def parse_train_list(path: str) -> List[Tuple[str,int]]:\n",
        "    # trainlist01.txt: \"ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi 1\"\n",
        "    items = []\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            rel, cls_idx_1based = line.strip().split()\n",
        "            cls = int(cls_idx_1based) - 1\n",
        "            items.append((rel, cls))\n",
        "    return items\n",
        "\n",
        "def parse_test_list(path: str) -> List[Tuple[str,int]]:\n",
        "    # testlist01.txt: \"ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\"\n",
        "    items = []\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            rel = line.strip()\n",
        "            cls_name = rel.split(\"/\")[0]\n",
        "            cls = CLASS_TO_IDX[cls_name]\n",
        "            items.append((rel, cls))\n",
        "    return items\n",
        "\n",
        "train_items = parse_train_list(os.path.join(SPLITS_DIR, \"trainlist01.txt\"))\n",
        "test_items  = parse_test_list(os.path.join(SPLITS_DIR, \"testlist01.txt\"))\n",
        "\n",
        "print(\"Train videos:\", len(train_items), \"Test videos:\", len(test_items))\n",
        "print(\"Example:\", train_items[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReeW3FPht_rx",
        "outputId": "23f010de-f35e-42b5-fa5a-45719f2fa8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clip batch shape: torch.Size([24, 3, 32, 160, 160])\n",
            "Label batch shape: torch.Size([24])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3310352347.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  print(\"Label batch shape:\", torch.tensor(batch[1]).shape)\n"
          ]
        }
      ],
      "source": [
        "# --- Dataset + Dataloader block (corrected normalization broadcasting) ---\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from decord import VideoReader, cpu\n",
        "\n",
        "@dataclass\n",
        "class ClipCfg:\n",
        "    frames: int\n",
        "    stride: int\n",
        "    size: int\n",
        "    min_scale: float = 0.6\n",
        "    max_scale: float = 1.0\n",
        "    hflip_p: float = 0.5\n",
        "\n",
        "# IMPORTANT: these shapes are for x shaped (T, C, H, W)\n",
        "MEAN = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\n",
        "STD  = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\n",
        "\n",
        "def load_clip(video_path: str, frames: int, stride: int, start: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns: (T, H, W, 3) uint8\n",
        "    \"\"\"\n",
        "    vr = VideoReader(video_path, ctx=cpu(0))\n",
        "    n = len(vr)\n",
        "    span = (frames - 1) * stride + 1\n",
        "\n",
        "    if n <= 0:\n",
        "        raise RuntimeError(f\"Empty video: {video_path}\")\n",
        "\n",
        "    if n >= span:\n",
        "        start = min(max(start, 0), n - span)\n",
        "        idxs = [start + i * stride for i in range(frames)]\n",
        "    else:\n",
        "        idxs = list(range(0, n, stride))\n",
        "        if len(idxs) == 0:\n",
        "            idxs = [0]\n",
        "        while len(idxs) < frames:\n",
        "            idxs.append(idxs[-1])\n",
        "        idxs = idxs[:frames]\n",
        "\n",
        "    return vr.get_batch(idxs).asnumpy()\n",
        "\n",
        "def clip_augment(frames_np: np.ndarray, cfg: ClipCfg, train: bool) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    frames_np: (T, H, W, 3) uint8\n",
        "    returns:   (C, T, cfg.size, cfg.size) float32 normalized\n",
        "    \"\"\"\n",
        "    x = torch.from_numpy(frames_np).permute(0, 3, 1, 2).float() / 255.0  # (T,C,H,W)\n",
        "\n",
        "    if train:\n",
        "        # Consistent random resized crop across the whole clip\n",
        "        T, C, H, W = x.shape\n",
        "        scale = random.uniform(cfg.min_scale, cfg.max_scale)\n",
        "        new_h = max(int(H * scale), cfg.size)\n",
        "        new_w = max(int(W * scale), cfg.size)\n",
        "\n",
        "        top = random.randint(0, max(0, H - new_h))\n",
        "        left = random.randint(0, max(0, W - new_w))\n",
        "\n",
        "        x = x[:, :, top:top+new_h, left:left+new_w]\n",
        "        x = F.interpolate(x, size=(cfg.size, cfg.size), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        if random.random() < cfg.hflip_p:\n",
        "            x = torch.flip(x, dims=[3])  # flip width\n",
        "    else:\n",
        "        x = F.interpolate(x, size=(cfg.size, cfg.size), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "    # ✅ Normalize while x is (T,C,H,W) so MEAN/STD broadcast correctly\n",
        "    x = (x - MEAN) / STD\n",
        "\n",
        "    # Return (C,T,H,W)\n",
        "    x = x.permute(1, 0, 2, 3).contiguous()\n",
        "    return x\n",
        "\n",
        "class UCF101Clips(Dataset):\n",
        "    def __init__(self, items, videos_root, clip_cfg: ClipCfg, train: bool):\n",
        "        self.items = items\n",
        "        self.videos_root = videos_root\n",
        "        self.cfg = clip_cfg\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rel, label = self.items[idx]\n",
        "        path = os.path.join(self.videos_root, rel)\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing video: {path}\")\n",
        "\n",
        "        start = random.randint(0, 10_000_000) if self.train else 0\n",
        "        frames = load_clip(path, self.cfg.frames, self.cfg.stride, start)\n",
        "        clip = clip_augment(frames, self.cfg, train=self.train)\n",
        "        return clip, label\n",
        "\n",
        "clip_cfg = ClipCfg(frames=CFG[\"frames\"], stride=CFG[\"stride\"], size=CFG[\"size\"])\n",
        "\n",
        "train_ds = UCF101Clips(train_items, VIDEOS_ROOT, clip_cfg, train=True)\n",
        "test_ds  = UCF101Clips(test_items,  VIDEOS_ROOT, clip_cfg, train=False)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=CFG[\"batch\"],\n",
        "    shuffle=True,\n",
        "    num_workers=CFG[\"workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=(CFG[\"workers\"] > 0),\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=CFG[\"batch\"],\n",
        "    shuffle=False,\n",
        "    num_workers=CFG[\"workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=(CFG[\"workers\"] > 0),\n",
        ")\n",
        "\n",
        "# Sanity check\n",
        "batch = next(iter(train_loader))\n",
        "print(\"Clip batch shape:\", batch[0].shape)  # (B,C,T,H,W)\n",
        "print(\"Label batch shape:\", torch.tensor(batch[1]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2uaOlfft_kO",
        "outputId": "add99f62-e538-46d1-cc65-b8df7d6b6cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params (M): 7.069221\n",
            "torch.compile enabled\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class R2Plus1DBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.spatial = nn.Conv3d(in_ch, out_ch, kernel_size=(1,3,3),\n",
        "                                 stride=(1,stride,stride), padding=(0,1,1), bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(out_ch)\n",
        "\n",
        "        self.temporal = nn.Conv3d(out_ch, out_ch, kernel_size=(3,1,1),\n",
        "                                  stride=(1,1,1), padding=(1,0,0), bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(out_ch)\n",
        "\n",
        "        self.down = None\n",
        "        if in_ch != out_ch or stride != 1:\n",
        "            self.down = nn.Sequential(\n",
        "                nn.Conv3d(in_ch, out_ch, kernel_size=1, stride=(1,stride,stride), bias=False),\n",
        "                nn.BatchNorm3d(out_ch)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = F.relu(self.bn1(self.spatial(x)))\n",
        "        x = self.bn2(self.temporal(x))\n",
        "        if self.down is not None:\n",
        "            identity = self.down(identity)\n",
        "        return F.relu(x + identity)\n",
        "\n",
        "class R2Plus1DNet(nn.Module):\n",
        "    def __init__(self, num_classes=101):\n",
        "        super().__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv3d(3, 64, kernel_size=(3,7,7), stride=(1,2,2), padding=(1,3,3), bias=False),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool3d(kernel_size=(1,3,3), stride=(1,2,2), padding=(0,1,1)),\n",
        "        )\n",
        "        self.layer1 = nn.Sequential(R2Plus1DBlock(64, 64),  R2Plus1DBlock(64, 64))\n",
        "        self.layer2 = nn.Sequential(R2Plus1DBlock(64, 128, stride=2), R2Plus1DBlock(128, 128))\n",
        "        self.layer3 = nn.Sequential(R2Plus1DBlock(128, 256, stride=2), R2Plus1DBlock(256, 256))\n",
        "        self.layer4 = nn.Sequential(R2Plus1DBlock(256, 512, stride=2), R2Plus1DBlock(512, 512))\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((1,1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        self._init()\n",
        "\n",
        "    def _init(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01); nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        return self.head(x)\n",
        "\n",
        "model = R2Plus1DNet(num_classes=101).to(device)\n",
        "print(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
        "\n",
        "# Optional speed-up on A100 (PyTorch 2.x)\n",
        "try:\n",
        "    model = torch.compile(model)\n",
        "    print(\"torch.compile enabled\")\n",
        "except Exception as e:\n",
        "    print(\"torch.compile not enabled:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77i-lnbgt_cd",
        "outputId": "df6f615e-5dd7-48c4-afa8-46af7ea650f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-564535810.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-564535810.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "/tmp/ipython-input-564535810.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py:312: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 001/100 | lr 0.02400 | loss 4.4383 | TEST clip Top1 7.67% Top5 23.26% | 279.2s | best 7.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-564535810.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 002/100 | lr 0.04800 | loss 3.9967 | TEST clip Top1 12.40% Top5 34.02% | 219.0s | best 12.40%\n",
            "Ep 003/100 | lr 0.07200 | loss 3.7082 | TEST clip Top1 17.05% Top5 42.51% | 219.1s | best 17.05%\n",
            "Ep 004/100 | lr 0.09600 | loss 3.4826 | TEST clip Top1 17.84% Top5 44.83% | 219.6s | best 17.84%\n",
            "Ep 005/100 | lr 0.12000 | loss 3.2671 | TEST clip Top1 22.31% Top5 52.05% | 218.6s | best 22.31%\n",
            "Ep 006/100 | lr 0.12000 | loss 3.0062 | TEST clip Top1 26.67% Top5 56.60% | 218.9s | best 26.67%\n",
            "Ep 007/100 | lr 0.11997 | loss 2.7622 | TEST clip Top1 29.39% Top5 60.40% | 218.6s | best 29.39%\n",
            "Ep 008/100 | lr 0.11987 | loss 2.5578 | TEST clip Top1 30.27% Top5 59.93% | 219.2s | best 30.27%\n",
            "Ep 009/100 | lr 0.11970 | loss 2.3826 | TEST clip Top1 31.64% Top5 63.28% | 218.5s | best 31.64%\n",
            "Ep 010/100 | lr 0.11948 | loss 2.2304 | TEST clip Top1 29.76% Top5 60.61% | 218.7s | best 31.64%\n",
            "Ep 011/100 | lr 0.11918 | loss 2.1095 | TEST clip Top1 34.13% Top5 62.65% | 219.8s | best 34.13%\n",
            "Ep 012/100 | lr 0.11882 | loss 1.9864 | TEST clip Top1 36.35% Top5 64.31% | 218.9s | best 36.35%\n",
            "Ep 013/100 | lr 0.11840 | loss 1.8829 | TEST clip Top1 38.12% Top5 65.16% | 218.8s | best 38.12%\n",
            "Ep 014/100 | lr 0.11791 | loss 1.7986 | TEST clip Top1 39.68% Top5 68.20% | 218.6s | best 39.68%\n",
            "Ep 015/100 | lr 0.11736 | loss 1.7213 | TEST clip Top1 35.45% Top5 62.78% | 217.8s | best 39.68%\n",
            "Ep 016/100 | lr 0.11675 | loss 1.6630 | TEST clip Top1 40.60% Top5 67.54% | 219.0s | best 40.60%\n",
            "Ep 017/100 | lr 0.11607 | loss 1.5952 | TEST clip Top1 39.94% Top5 68.91% | 218.6s | best 40.60%\n",
            "Ep 018/100 | lr 0.11534 | loss 1.5343 | TEST clip Top1 42.69% Top5 69.02% | 218.0s | best 42.69%\n",
            "Ep 019/100 | lr 0.11454 | loss 1.4994 | TEST clip Top1 40.21% Top5 67.22% | 218.5s | best 42.69%\n",
            "Ep 020/100 | lr 0.11368 | loss 1.4630 | TEST clip Top1 39.73% Top5 67.70% | 219.4s | best 42.69%\n",
            "Ep 021/100 | lr 0.11277 | loss 1.4207 | TEST clip Top1 41.00% Top5 67.72% | 219.7s | best 42.69%\n",
            "Ep 022/100 | lr 0.11180 | loss 1.3908 | TEST clip Top1 42.93% Top5 69.73% | 219.7s | best 42.93%\n",
            "Ep 023/100 | lr 0.11077 | loss 1.3608 | TEST clip Top1 42.16% Top5 68.62% | 218.2s | best 42.93%\n",
            "Ep 024/100 | lr 0.10968 | loss 1.3559 | TEST clip Top1 42.69% Top5 69.94% | 219.5s | best 42.93%\n",
            "Ep 025/100 | lr 0.10854 | loss 1.3456 | TEST clip Top1 40.44% Top5 67.49% | 218.4s | best 42.93%\n",
            "Ep 026/100 | lr 0.10735 | loss 1.2993 | TEST clip Top1 43.11% Top5 68.60% | 218.9s | best 43.11%\n",
            "Ep 027/100 | lr 0.10610 | loss 1.2838 | TEST clip Top1 45.04% Top5 70.87% | 218.1s | best 45.04%\n",
            "Ep 028/100 | lr 0.10481 | loss 1.2618 | TEST clip Top1 42.08% Top5 71.16% | 218.6s | best 45.04%\n",
            "Ep 029/100 | lr 0.10347 | loss 1.2512 | TEST clip Top1 45.41% Top5 71.11% | 218.2s | best 45.41%\n",
            "Ep 030/100 | lr 0.10207 | loss 1.2000 | TEST clip Top1 45.28% Top5 71.56% | 217.9s | best 45.41%\n",
            "Ep 031/100 | lr 0.10064 | loss 1.1903 | TEST clip Top1 44.41% Top5 71.61% | 218.6s | best 45.41%\n",
            "Ep 032/100 | lr 0.09916 | loss 1.1985 | TEST clip Top1 43.54% Top5 70.47% | 219.4s | best 45.41%\n",
            "Ep 033/100 | lr 0.09763 | loss 1.1965 | TEST clip Top1 42.90% Top5 68.54% | 218.2s | best 45.41%\n",
            "Ep 034/100 | lr 0.09606 | loss 1.1729 | TEST clip Top1 43.93% Top5 71.61% | 217.6s | best 45.41%\n",
            "Ep 035/100 | lr 0.09446 | loss 1.1582 | TEST clip Top1 47.18% Top5 72.24% | 219.3s | best 47.18%\n",
            "Ep 036/100 | lr 0.09282 | loss 1.1345 | TEST clip Top1 45.15% Top5 72.35% | 219.4s | best 47.18%\n",
            "Ep 037/100 | lr 0.09114 | loss 1.1412 | TEST clip Top1 44.91% Top5 71.45% | 218.4s | best 47.18%\n",
            "Ep 038/100 | lr 0.08943 | loss 1.1364 | TEST clip Top1 43.96% Top5 71.03% | 218.5s | best 47.18%\n",
            "Ep 039/100 | lr 0.08768 | loss 1.1291 | TEST clip Top1 46.58% Top5 72.54% | 218.4s | best 47.18%\n",
            "Ep 040/100 | lr 0.08591 | loss 1.1020 | TEST clip Top1 47.18% Top5 72.64% | 218.3s | best 47.18%\n",
            "Ep 041/100 | lr 0.08410 | loss 1.1071 | TEST clip Top1 44.89% Top5 71.42% | 218.2s | best 47.18%\n",
            "Ep 042/100 | lr 0.08227 | loss 1.0842 | TEST clip Top1 45.81% Top5 70.53% | 219.2s | best 47.18%\n",
            "Ep 043/100 | lr 0.08042 | loss 1.0797 | TEST clip Top1 48.03% Top5 73.51% | 219.4s | best 48.03%\n",
            "Ep 044/100 | lr 0.07854 | loss 1.0586 | TEST clip Top1 49.17% Top5 73.78% | 219.9s | best 49.17%\n",
            "Ep 045/100 | lr 0.07664 | loss 1.0504 | TEST clip Top1 47.61% Top5 73.70% | 218.7s | best 49.17%\n",
            "Ep 046/100 | lr 0.07473 | loss 1.0365 | TEST clip Top1 47.53% Top5 73.38% | 219.0s | best 49.17%\n",
            "Ep 047/100 | lr 0.07280 | loss 1.0359 | TEST clip Top1 47.79% Top5 72.24% | 219.6s | best 49.17%\n",
            "Ep 048/100 | lr 0.07085 | loss 1.0279 | TEST clip Top1 48.64% Top5 74.91% | 219.6s | best 49.17%\n",
            "Ep 049/100 | lr 0.06890 | loss 1.0319 | TEST clip Top1 49.17% Top5 74.07% | 220.0s | best 49.17%\n",
            "Ep 050/100 | lr 0.06693 | loss 1.0151 | TEST clip Top1 49.33% Top5 74.70% | 220.1s | best 49.33%\n",
            "Ep 051/100 | lr 0.06495 | loss 1.0054 | TEST clip Top1 50.57% Top5 75.89% | 219.3s | best 50.57%\n",
            "Ep 052/100 | lr 0.06298 | loss 0.9992 | TEST clip Top1 49.33% Top5 75.50% | 219.7s | best 50.57%\n",
            "Ep 053/100 | lr 0.06099 | loss 0.9936 | TEST clip Top1 50.57% Top5 75.23% | 219.7s | best 50.57%\n",
            "Ep 054/100 | lr 0.05901 | loss 0.9801 | TEST clip Top1 48.98% Top5 74.83% | 219.1s | best 50.57%\n",
            "Ep 055/100 | lr 0.05702 | loss 0.9805 | TEST clip Top1 49.85% Top5 75.87% | 218.5s | best 50.57%\n",
            "Ep 056/100 | lr 0.05505 | loss 0.9738 | TEST clip Top1 50.67% Top5 74.17% | 218.1s | best 50.67%\n",
            "Ep 057/100 | lr 0.05307 | loss 0.9695 | TEST clip Top1 51.20% Top5 75.52% | 218.5s | best 51.20%\n",
            "Ep 058/100 | lr 0.05110 | loss 0.9562 | TEST clip Top1 50.41% Top5 74.57% | 219.1s | best 51.20%\n",
            "Ep 059/100 | lr 0.04915 | loss 0.9567 | TEST clip Top1 51.04% Top5 75.13% | 218.0s | best 51.20%\n",
            "Ep 060/100 | lr 0.04720 | loss 0.9458 | TEST clip Top1 51.31% Top5 76.21% | 218.5s | best 51.31%\n",
            "Ep 061/100 | lr 0.04527 | loss 0.9480 | TEST clip Top1 51.39% Top5 75.20% | 217.6s | best 51.39%\n",
            "Ep 062/100 | lr 0.04336 | loss 0.9417 | TEST clip Top1 52.55% Top5 76.69% | 217.8s | best 52.55%\n",
            "Ep 063/100 | lr 0.04146 | loss 0.9301 | TEST clip Top1 51.18% Top5 75.52% | 218.0s | best 52.55%\n",
            "Ep 064/100 | lr 0.03958 | loss 0.9218 | TEST clip Top1 52.31% Top5 75.71% | 218.6s | best 52.55%\n",
            "Ep 065/100 | lr 0.03773 | loss 0.9130 | TEST clip Top1 51.81% Top5 75.18% | 218.0s | best 52.55%\n",
            "Ep 066/100 | lr 0.03590 | loss 0.9125 | TEST clip Top1 51.41% Top5 75.76% | 217.4s | best 52.55%\n",
            "Ep 067/100 | lr 0.03409 | loss 0.9067 | TEST clip Top1 52.66% Top5 77.61% | 217.9s | best 52.66%\n",
            "Ep 068/100 | lr 0.03232 | loss 0.9041 | TEST clip Top1 53.74% Top5 76.39% | 217.4s | best 53.74%\n",
            "Ep 069/100 | lr 0.03057 | loss 0.9034 | TEST clip Top1 53.08% Top5 78.09% | 217.8s | best 53.74%\n",
            "Ep 070/100 | lr 0.02886 | loss 0.9002 | TEST clip Top1 51.57% Top5 76.90% | 217.7s | best 53.74%\n",
            "Ep 071/100 | lr 0.02718 | loss 0.8940 | TEST clip Top1 54.08% Top5 78.35% | 219.0s | best 54.08%\n",
            "Ep 072/100 | lr 0.02554 | loss 0.8904 | TEST clip Top1 53.69% Top5 77.74% | 218.8s | best 54.08%\n",
            "Ep 073/100 | lr 0.02394 | loss 0.8877 | TEST clip Top1 53.87% Top5 77.50% | 219.4s | best 54.08%\n",
            "Ep 074/100 | lr 0.02237 | loss 0.8827 | TEST clip Top1 55.54% Top5 78.61% | 220.5s | best 55.54%\n",
            "Ep 075/100 | lr 0.02084 | loss 0.8786 | TEST clip Top1 53.95% Top5 78.24% | 218.4s | best 55.54%\n",
            "Ep 076/100 | lr 0.01936 | loss 0.8772 | TEST clip Top1 54.00% Top5 78.67% | 217.3s | best 55.54%\n",
            "Ep 077/100 | lr 0.01793 | loss 0.8747 | TEST clip Top1 54.48% Top5 78.72% | 218.9s | best 55.54%\n",
            "Ep 078/100 | lr 0.01653 | loss 0.8754 | TEST clip Top1 54.35% Top5 78.40% | 218.1s | best 55.54%\n",
            "Ep 079/100 | lr 0.01519 | loss 0.8705 | TEST clip Top1 55.33% Top5 79.28% | 218.0s | best 55.54%\n",
            "Ep 080/100 | lr 0.01390 | loss 0.8679 | TEST clip Top1 55.01% Top5 78.56% | 218.2s | best 55.54%\n",
            "Ep 081/100 | lr 0.01265 | loss 0.8637 | TEST clip Top1 55.56% Top5 79.06% | 217.4s | best 55.56%\n",
            "Ep 082/100 | lr 0.01146 | loss 0.8620 | TEST clip Top1 54.22% Top5 78.06% | 218.3s | best 55.56%\n",
            "Ep 083/100 | lr 0.01032 | loss 0.8627 | TEST clip Top1 55.19% Top5 79.09% | 219.0s | best 55.56%\n",
            "Ep 084/100 | lr 0.00923 | loss 0.8617 | TEST clip Top1 55.51% Top5 79.30% | 218.8s | best 55.56%\n",
            "Ep 085/100 | lr 0.00820 | loss 0.8565 | TEST clip Top1 55.43% Top5 79.70% | 218.1s | best 55.56%\n",
            "Ep 086/100 | lr 0.00723 | loss 0.8580 | TEST clip Top1 54.56% Top5 78.93% | 218.0s | best 55.56%\n",
            "Ep 087/100 | lr 0.00632 | loss 0.8550 | TEST clip Top1 55.62% Top5 79.41% | 217.8s | best 55.62%\n",
            "Ep 088/100 | lr 0.00546 | loss 0.8546 | TEST clip Top1 55.35% Top5 79.09% | 218.4s | best 55.62%\n",
            "Ep 089/100 | lr 0.00466 | loss 0.8549 | TEST clip Top1 55.67% Top5 79.38% | 218.7s | best 55.67%\n",
            "Ep 090/100 | lr 0.00393 | loss 0.8530 | TEST clip Top1 56.17% Top5 80.02% | 217.8s | best 56.17%\n",
            "Ep 091/100 | lr 0.00325 | loss 0.8518 | TEST clip Top1 55.59% Top5 79.36% | 217.9s | best 56.17%\n",
            "Ep 092/100 | lr 0.00264 | loss 0.8497 | TEST clip Top1 55.91% Top5 79.75% | 218.3s | best 56.17%\n",
            "Ep 093/100 | lr 0.00209 | loss 0.8504 | TEST clip Top1 55.91% Top5 80.17% | 217.6s | best 56.17%\n",
            "Ep 094/100 | lr 0.00160 | loss 0.8508 | TEST clip Top1 55.70% Top5 79.43% | 217.0s | best 56.17%\n",
            "Ep 095/100 | lr 0.00118 | loss 0.8503 | TEST clip Top1 56.12% Top5 79.28% | 217.3s | best 56.17%\n",
            "Ep 096/100 | lr 0.00082 | loss 0.8488 | TEST clip Top1 56.17% Top5 79.54% | 217.6s | best 56.17%\n",
            "Ep 097/100 | lr 0.00052 | loss 0.8498 | TEST clip Top1 55.70% Top5 79.94% | 217.8s | best 56.17%\n",
            "Ep 098/100 | lr 0.00030 | loss 0.8496 | TEST clip Top1 55.80% Top5 79.94% | 217.8s | best 56.17%\n",
            "Ep 099/100 | lr 0.00013 | loss 0.8485 | TEST clip Top1 55.67% Top5 79.91% | 217.8s | best 56.17%\n",
            "Ep 100/100 | lr 0.00003 | loss 0.8501 | TEST clip Top1 55.78% Top5 79.33% | 217.1s | best 56.17%\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def topk_acc(logits, targets, ks=(1,5)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(ks)\n",
        "        pred = logits.topk(maxk, dim=1).indices\n",
        "        correct = pred.eq(targets.view(-1,1))\n",
        "        out = []\n",
        "        for k in ks:\n",
        "            out.append(correct[:, :k].any(dim=1).float().mean().item())\n",
        "        return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_clip(model, loader):\n",
        "    model.eval()\n",
        "    s1=s5=n=0\n",
        "    for x,y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, device=device)\n",
        "        logits = model(x)\n",
        "        a1,a5 = topk_acc(logits, y, ks=(1,5))\n",
        "        b = x.size(0)\n",
        "        s1 += a1*b; s5 += a5*b; n += b\n",
        "    return s1/n, s5/n\n",
        "\n",
        "def train_one_epoch(model, loader, opt, scaler, epoch, total_epochs):\n",
        "    model.train()\n",
        "    t0=time()\n",
        "    total_loss=0.0\n",
        "    step=0\n",
        "\n",
        "    for x,y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, device=device)\n",
        "\n",
        "        with autocast():\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y, label_smoothing=CFG[\"label_smoothing\"])\n",
        "            loss = loss / CFG[\"grad_accum\"]\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        step += 1\n",
        "        if step % CFG[\"grad_accum\"] == 0:\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        total_loss += loss.item() * x.size(0) * CFG[\"grad_accum\"]\n",
        "\n",
        "    dt=time()-t0\n",
        "    return total_loss/len(loader.dataset), dt\n",
        "\n",
        "# Optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=CFG[\"lr\"], momentum=0.9, weight_decay=CFG[\"weight_decay\"])\n",
        "scaler = GradScaler()\n",
        "\n",
        "# LR schedule: warmup then cosine\n",
        "def lr_at_epoch(ep):\n",
        "    if ep < CFG[\"warmup_epochs\"]:\n",
        "        return (ep + 1) / CFG[\"warmup_epochs\"]\n",
        "    progress = (ep - CFG[\"warmup_epochs\"]) / max(1, (CFG[\"epochs\"] - CFG[\"warmup_epochs\"]))\n",
        "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "best_vtop1 = 0.0\n",
        "ckpt_path = \"/content/r2plus1d_ucf101_best.pt\"\n",
        "\n",
        "for ep in range(CFG[\"epochs\"]):\n",
        "    # set LR\n",
        "    lr_scale = lr_at_epoch(ep)\n",
        "    for pg in opt.param_groups:\n",
        "        pg[\"lr\"] = CFG[\"lr\"] * lr_scale\n",
        "\n",
        "    loss, dt = train_one_epoch(model, train_loader, opt, scaler, ep, CFG[\"epochs\"])\n",
        "    top1, top5 = eval_clip(model, test_loader)\n",
        "\n",
        "    if top1 > best_vtop1:\n",
        "        best_vtop1 = top1\n",
        "        torch.save({\"model\": model.state_dict(), \"epoch\": ep+1, \"clip_top1\": top1}, ckpt_path)\n",
        "\n",
        "    print(f\"Ep {ep+1:03d}/{CFG['epochs']} | lr {opt.param_groups[0]['lr']:.5f} | loss {loss:.4f} | \"\n",
        "          f\"TEST clip Top1 {top1*100:.2f}% Top5 {top5*100:.2f}% | {dt:.1f}s | best {best_vtop1*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jwv0aFGUt-9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01dab862-6267-4d02-fccc-fe08d86b135a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video-level (10 clips/video): Top1 59.13% | Top5 82.24%\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def predict_video_logits(model, video_path, cfg: ClipCfg, n_clips=10):\n",
        "    model.eval()\n",
        "    vr = VideoReader(video_path, ctx=cpu(0))\n",
        "    n = len(vr)\n",
        "    span = (cfg.frames - 1) * cfg.stride + 1\n",
        "\n",
        "    if n <= span:\n",
        "        starts = [0]*n_clips\n",
        "    else:\n",
        "        max_start = n - span\n",
        "        starts = np.linspace(0, max_start, num=n_clips).astype(int).tolist()\n",
        "\n",
        "    logits_all = []\n",
        "    for s in starts:\n",
        "        frames = load_clip(video_path, cfg.frames, cfg.stride, s)\n",
        "        clip = clip_augment(frames, cfg, train=False).unsqueeze(0).to(device)\n",
        "        logits_all.append(model(clip))\n",
        "    return torch.mean(torch.cat(logits_all, dim=0), dim=0, keepdim=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_video_level(model, items, videos_root, cfg: ClipCfg, n_clips=10):\n",
        "    model.eval()\n",
        "    c1=c5=0\n",
        "    for rel, y in items:\n",
        "        path = os.path.join(videos_root, rel)\n",
        "        logits = predict_video_logits(model, path, cfg, n_clips=n_clips)\n",
        "        top5 = logits.topk(5, dim=1).indices.squeeze(0).tolist()\n",
        "        c1 += int(top5[0] == y)\n",
        "        c5 += int(y in top5)\n",
        "    return c1/len(items), c5/len(items)\n",
        "\n",
        "# Load best and run video-level eval\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(ckpt[\"model\"])\n",
        "\n",
        "v1, v5 = eval_video_level(model, test_items, VIDEOS_ROOT, clip_cfg, n_clips=CFG[\"nclips_eval\"])\n",
        "print(f\"Video-level ({CFG['nclips_eval']} clips/video): Top1 {v1*100:.2f}% | Top5 {v5*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kNdis-WNt-zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d079fd5-50d8-4629-b5d3-617adc448c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: PullUps/v_PullUps_g01_c01.avi\n",
            "GT: PullUps\n",
            "Top-5:\n",
            "  Mixing                     0.095\n",
            "  PlayingTabla               0.059\n",
            "  CleanAndJerk               0.045\n",
            "  PlayingViolin              0.042\n",
            "  BlowDryHair                0.039\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def demo_one():\n",
        "    rel, y = random.choice(test_items)\n",
        "    path = os.path.join(VIDEOS_ROOT, rel)\n",
        "    logits = predict_video_logits(model, path, clip_cfg, n_clips=CFG[\"nclips_eval\"])\n",
        "    probs = torch.softmax(logits, dim=1).squeeze(0)\n",
        "    vals, idxs = torch.topk(probs, k=5)\n",
        "\n",
        "    print(\"Video:\", rel)\n",
        "    print(\"GT:\", IDX_TO_CLASS[y])\n",
        "    print(\"Top-5:\")\n",
        "    for p,i in zip(vals.tolist(), idxs.tolist()):\n",
        "        print(f\"  {IDX_TO_CLASS[i]:25s}  {p:.3f}\")\n",
        "\n",
        "demo_one()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X3i9IuKuuTtM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}