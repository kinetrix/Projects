In this project, I've built an LSTM model that is used to recognize Speech Emotion.
The model is trained on the TESS(Toronto Emotional Speech Set) dataset. The Dataset has 7 Emotions with 800 sample audios each(audio samples of 2 individuals - 400 each).
I've used Mel-frequency cepstral coefficients (MFCCs) for feature extraction.
As usual, the dataset is split 80 - 20 for training and testing respectively.
This model gave me a Validation Accuracy of almost 99%.
